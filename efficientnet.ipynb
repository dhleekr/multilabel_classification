{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"efficientnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S76sGVkhxrtE","executionInfo":{"status":"ok","timestamp":1614497737131,"user_tz":-540,"elapsed":17262,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"325a0401-b1ed-44cc-ff15-6a04ac35dcdc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lg0Rn7l54foQ","executionInfo":{"status":"ok","timestamp":1614497738988,"user_tz":-540,"elapsed":559,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"e649570e-fd58-45a9-b167-c907028a6957"},"source":["cd drive/My Drive/dacon"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/dacon\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bsBqc7w7_HA8"},"source":["## 1. 데이터 불러오기"]},{"cell_type":"code","metadata":{"id":"0lFSzTFd0qGc","executionInfo":{"status":"ok","timestamp":1614497740778,"user_tz":-540,"elapsed":579,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}}},"source":["from google.colab import output\r\n","# !cp 파일1 파일2 # 파일1을 파일2로 복사 붙여넣기\r\n","#!cp \"/content/drive/MyDrive/월간데이콘 12/data/open/data_2.zip\" \"data_2.zip\"\r\n","# data_2.zip을 현재 디렉터리에 압축해제\r\n","# !unzip \"data.zip\""],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"gWh_EqOX6fy-","executionInfo":{"status":"ok","timestamp":1614498462356,"user_tz":-540,"elapsed":720489,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}}},"source":["# from google.colab import output\r\n","# # 현재 디렉터리에 dirty_mnist라는 폴더 생성\r\n","!mkdir \"./dirty_mnist\"\r\n","# #dirty_mnist.zip라는 zip파일을 dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"dirty_mnist_2nd.zip\" -d \"./dirty_mnist/\"\r\n","# # 현재 디렉터리에 test_dirty_mnist라는 폴더 생성\r\n","!mkdir \"./test_dirty_mnist\"\r\n","# #test_dirty_mnist.zip라는 zip파일을 test_dirty_mnist라는 폴더에 압축 풀기\r\n","!unzip \"test_dirty_mnist_2nd.zip\" -d \"./test_dirty_mnist/\"\r\n","# # 출력 결과 지우기\r\n","output.clear()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PQczrv4m0Ok","executionInfo":{"status":"ok","timestamp":1614498469893,"user_tz":-540,"elapsed":531,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}}},"source":["!mkdir \"./models\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RQQkPTZm6Lg","executionInfo":{"status":"ok","timestamp":1614498474397,"user_tz":-540,"elapsed":539,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"6c7a6fc9-18ba-4778-ce66-72c4c3c06005"},"source":["ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":[" 10.pth                      'EfficientNet_0.927(1).pth'\n"," 11.pth                      'EfficientNet_0.927(2).csv'\n"," 12.pth                      'EfficientNet_0.927(2).pth'\n"," 13.pth                       EfficientNet_0.927.csv\n"," 14.pth                       EfficientNet_0.927.pth\n"," data_2.zip                   EfficientNet_0.928.csv\n"," \u001b[0m\u001b[01;34mdirty_mnist\u001b[0m/                 EfficientNet_0.928.pth\n"," dirty_mnist_2nd_answer.csv   mnist_data.zip\n"," dirty_mnist_2nd.zip          \u001b[01;34mmodels\u001b[0m/\n"," EfficientNet_0.926.csv       sample_submission.csv\n"," EfficientNet_0.926.pth       \u001b[01;34mtest_dirty_mnist\u001b[0m/\n","'EfficientNet_0.927(1).csv'   test_dirty_mnist_2nd.zip\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eHtkYutm_Jfo"},"source":["## 2. Library Import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"27YGG5U4YMeU","executionInfo":{"status":"ok","timestamp":1614498482875,"user_tz":-540,"elapsed":4725,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"0868a4e2-f7f9-4bda-8ea3-9988d2b35d02"},"source":["!pip install efficientnet_pytorch"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting efficientnet_pytorch\n","  Downloading https://files.pythonhosted.org/packages/4e/83/f9c5f44060f996279e474185ebcbd8dbd91179593bffb9abe3afa55d085b/efficientnet_pytorch-0.7.0.tar.gz\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.7.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n","Building wheels for collected packages: efficientnet-pytorch\n","  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.0-cp37-none-any.whl size=16031 sha256=851984d6897990bfb9d2d0349222b19d1641beb1140cadb2a41a0d128e0eb655\n","  Stored in directory: /root/.cache/pip/wheels/e9/c6/e1/7a808b26406239712cfce4b5ceeb67d9513ae32aa4b31445c6\n","Successfully built efficientnet-pytorch\n","Installing collected packages: efficientnet-pytorch\n","Successfully installed efficientnet-pytorch-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_RPgJyf8_QSu","executionInfo":{"status":"ok","timestamp":1614498489495,"user_tz":-540,"elapsed":4855,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}}},"source":["import pandas as pd\r\n","import numpy as np\r\n","import matplotlib.pyplot as plt\r\n","import cv2\r\n","from tqdm import tqdm\r\n","import imutils\r\n","import zipfile\r\n","import os\r\n","from PIL import Image\r\n","\r\n","import torch\r\n","import torch.nn as nn\r\n","import torch.nn.functional as F\r\n","import torchvision.models as models\r\n","import torchvision.transforms as T\r\n","from torch.utils.data import DataLoader, Dataset\r\n","from google.colab import output\r\n","from efficientnet_pytorch import EfficientNet\r\n","\r\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # 디바이스 설정"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TR4Lr-ml_S1V"},"source":["## 3. Dataset 구성"]},{"cell_type":"code","metadata":{"id":"yq_wAhpKBR9E","executionInfo":{"status":"ok","timestamp":1614498490463,"user_tz":-540,"elapsed":3701,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}}},"source":["from typing import Tuple, Sequence, Callable\r\n","from torch import nn, Tensor\r\n","dirty_mnist_answer = pd.read_csv(\"dirty_mnist_2nd_answer.csv\")\r\n","# dirty_mnist라는 디렉터리 속에 들어있는 파일들의 이름을 \r\n","# namelist라는 변수에 저장\r\n","namelist = os.listdir('./dirty_mnist/')\r\n","\r\n","# unmpy를 tensor로 변환하는 ToTensor 정의\r\n","class ToTensor(object):\r\n","    \"\"\"numpy array를 tensor(torch)로 변환합니다.\"\"\"\r\n","    def __call__(self, sample):\r\n","        label = sample['label']\r\n","        # swap color axis because\r\n","        # numpy image: H x W x C\r\n","        # torch image: C X H X W\r\n","        #image = image.transpose((2, 0, 1))\r\n","        return torch.FloatTensor(label)\r\n","# to_tensor 선언\r\n","to_tensor = T.Compose([\r\n","                        # T.RandomHorizontalFlip(p=0.5),\r\n","                        # T.RandomVerticalFlip(p=0.5),\r\n","                        ToTensor(),\r\n","                        #T.Normalize((0.1307,),(0.3081,))\r\n","                         \r\n","                        \r\n","                        \r\n","                    ])\r\n","trans_train=T.Compose(\r\n","    [\r\n","     T.RandomAffine(180),\r\n","     T.ToTensor(),\r\n","     T.GaussianBlur((3,3)),\r\n","     T.Normalize((0.1307,),(0.3081,))\r\n","     \r\n","    ]\r\n",")\r\n","\r\n","trans_test=T.Compose(\r\n","    [\r\n","     T.ToTensor(),\r\n","     T.GaussianBlur((3,3)),\r\n","     T.Normalize((0.1307,),(0.3081,))\r\n","    ]\r\n",")\r\n","\r\n","class DatasetMNIST(torch.utils.data.Dataset):\r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms=None,#미리 선언한 to_tensor를 transforms로 받음\r\n","                 augmentations=None):\r\n","        \r\n","        self.dir_path = dir_path # 데이터의 이미지가 저장된 디렉터리 경로\r\n","        self.meta_df = meta_df # 데이터의 인덱스와 정답지가 들어있는 DataFrame\r\n","\r\n","        self.transforms = transforms# Transform\r\n","        self.augmentations = augmentations # Augmentation\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.meta_df)\r\n","    \r\n","    def __getitem__(self, index):\r\n","        # 폴더 경로 + 이미지 이름 + .png => 파일의 경로\r\n","        # 참고) \"12\".zfill(5) => 000012\r\n","        #       \"146\".zfill(5) => 000145\r\n","        # cv2.IMREAD_GRAYSCALE : png파일을 채널이 1개인 GRAYSCALE로 읽음\r\n","        \r\n","        image = cv2.imread(self.dir_path +\\\r\n","                          str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","                          cv2.IMREAD_GRAYSCALE)\r\n","        \r\n","        # 0 ~ 255의 값을 갖고 크기가 (256,256)인 numpy array를\r\n","        # 0 ~ 1 사이의 실수를 갖고 크기가 (256,256,1)인 numpy array로 변환\r\n","        \r\n","        # image = Image.fromarray(image)\r\n","        # 정답 numpy array생성(존재하면 1 없으면 0)\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","        label=torch.tensor(label)\r\n","        #image = (image).astype('float')[..., np.newaxis]\r\n","        image = Image.fromarray(image)\r\n","        \r\n","        image=trans_train(image)\r\n","        \r\n","        #label=self.transforms(label)\r\n","        sample = {'image': image, 'label': label}\r\n","\r\n","        # transform 적용\r\n","        # numpy to tensor\r\n","        # if self.transforms:\r\n","        #     sample = self.transforms(sample)\r\n","        \r\n","\r\n","        return sample\r\n","\r\n","class DatasetMNIST_test(torch.utils.data.Dataset):\r\n","    def __init__(self,\r\n","                 dir_path,\r\n","                 meta_df,\r\n","                 transforms=None,#미리 선언한 to_tensor를 transforms로 받음\r\n","                 augmentations=None):\r\n","        \r\n","        self.dir_path = dir_path # 데이터의 이미지가 저장된 디렉터리 경로\r\n","        self.meta_df = meta_df # 데이터의 인덱스와 정답지가 들어있는 DataFrame\r\n","\r\n","        self.transforms = transforms# Transform\r\n","        self.augmentations = augmentations # Augmentation\r\n","        \r\n","    def __len__(self):\r\n","        return len(self.meta_df)\r\n","    \r\n","    def __getitem__(self, index):\r\n","        # 폴더 경로 + 이미지 이름 + .png => 파일의 경로\r\n","        # 참고) \"12\".zfill(5) => 000012\r\n","        #       \"146\".zfill(5) => 000145\r\n","        # cv2.IMREAD_GRAYSCALE : png파일을 채널이 1개인 GRAYSCALE로 읽음\r\n","        \r\n","        image = cv2.imread(self.dir_path +\\\r\n","                          str(self.meta_df.iloc[index,0]).zfill(5) + '.png',\r\n","                          cv2.IMREAD_GRAYSCALE)\r\n","        \r\n","        # 0 ~ 255의 값을 갖고 크기가 (256,256)인 numpy array를\r\n","        # 0 ~ 1 사이의 실수를 갖고 크기가 (256,256,1)인 numpy array로 변환\r\n","        \r\n","        # image = Image.fromarray(image)\r\n","        # 정답 numpy array생성(존재하면 1 없으면 0)\r\n","        label = self.meta_df.iloc[index, 1:].values.astype('float')\r\n","        label=torch.tensor(label)\r\n","        #image = (image).astype('float')[..., np.newaxis]\r\n","        image = Image.fromarray(image)\r\n","        \r\n","        image=trans_test(image)\r\n","        \r\n","        #label=self.transforms(label)\r\n","        sample = {'image': image, 'label': label}\r\n","\r\n","        # transform 적용\r\n","        # numpy to tensor\r\n","        # if self.transforms:\r\n","        #     sample = self.transforms(sample)\r\n","        \r\n","\r\n","        return sample"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rfc-d5fF_ooY"},"source":["## 4. 학습 모델 구성"]},{"cell_type":"code","metadata":{"id":"CLghf9Vh32N0"},"source":["# nn.Module을 상속 받아 MultiLabelResnet를 정의\r\n","class MultiLabelResnet(nn.Module):\r\n","    def __init__(self):\r\n","        super(MultiLabelResnet, self).__init__()\r\n","        self.conv2d = nn.Conv2d(1, 3, 3, stride=1)\r\n","        # self.resnet = models.densenet121(pretrained=True)\r\n","        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b7')\r\n","        self.FC = nn.Linear(1000,26)\r\n","    \r\n","\r\n","    def forward(self, x):\r\n","        # resnet의 입력은 [3, N, N]으로\r\n","        # 3개의 채널을 갖기 때문에\r\n","        # resnet 입력 전에 conv2d를 한 층 추가\r\n","        x = F.relu(self.conv2d(x))\r\n","        x = F.relu(self.efficientnet(x))\r\n","\r\n","        # resnet18을 추가\r\n","        x = torch.sigmoid(self.FC(x))\r\n","\r\n","        # 마지막 출력에 nn.Linear를 추가\r\n","        # multilabel을 예측해야 하기 때문에\r\n","        # softmax가 아닌 sigmoid를 적용\r\n","        #x = torch.sigmoid(self.FC(x))\r\n","        return x\r\n","# 모델 선언\r\n","model = MultiLabelResnet()\r\n","model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8At8CaBw_s-O"},"source":["## 5. 학습"]},{"cell_type":"code","metadata":{"id":"Lf-9aNbagQoV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"abbcf1c1-0b74-44d6-d570-59fdb1114f5f"},"source":["# cross validation을 적용하기 위해 KFold 생성\r\n","from sklearn.model_selection import KFold\r\n","from sklearn.model_selection import train_test_split\r\n","kfold = KFold(n_splits=5, shuffle=True, random_state=0)\r\n","\r\n","#print(train_test_split(dirty_mnist_answer, test_size=0.3 , random_state=123))\r\n","\r\n","# dirty_mnist_answer에서 train_idx와 val_idx를 생성\r\n","best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\r\n","for fold_index, (trn_idx, val_idx) in enumerate(kfold.split(dirty_mnist_answer),1):\r\n","#for (trn_idx, val_idx) in enumerate(train_test_split(dirty_mnist_answer, test_size=0.3 , random_state=123)): \r\n","    #print(f'[fold: {fold_index}]')\r\n","    # cuda cache 초기화\r\n","    torch.cuda.empty_cache()\r\n","    #print(val_idx)\r\n","    #train fold, validation fold 분할\r\n","    train_answer = dirty_mnist_answer.iloc[trn_idx]\r\n","    test_answer  = dirty_mnist_answer.iloc[val_idx]\r\n","    #train_answer=trn_idx\r\n","    #test_answer=val_idx\r\n","    #print(test_answer)\r\n","    #print(train_answer)\r\n","    #Dataset 정의\r\n","    train_dataset = DatasetMNIST(\"dirty_mnist/\", train_answer)\r\n","    valid_dataset = DatasetMNIST_test(\"dirty_mnist/\", test_answer)\r\n","\r\n","    \r\n","\r\n","    #DataLoader 정의\r\n","    train_data_loader = DataLoader(\r\n","        train_dataset,\r\n","        batch_size = 16,\r\n","        shuffle = True,\r\n","        num_workers = 3\r\n","    )\r\n","    valid_data_loader = DataLoader(\r\n","        valid_dataset,\r\n","        batch_size = 16,\r\n","        shuffle = True,\r\n","        num_workers = 3\r\n","    )\r\n","  \r\n","\r\n","    # 모델 선언\r\n","    # model = MultiLabelResnet()\r\n","    # model.to(device)# gpu에 모델 할당\r\n","    model = torch.load('./EfficientNet_0.928.pth')\r\n","    model.to(device)\r\n","\r\n","    # 훈련 옵션 설정\r\n","    optimizer = torch.optim.Adam(model.parameters(),\r\n","                                lr = 0.0001,\r\n","                                 weight_decay=0\r\n","                                 )\r\n","    # 0 <= epoch < 5 -> 0.0005, 5 <= epoch < 10 -> 0.0005 * 0.75 ...\r\n","    # lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\r\n","    #                                              step_size = 5,\r\n","    #                                              gamma = 0.9)\r\n","\r\n","    lr_scheduler= torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\r\n","    criterion = torch.nn.MSELoss()\r\n","    \r\n","    # 훈련 시작\r\n","    valid_acc_max = 0\r\n","    for epoch in range(20):\r\n","        # 1개 epoch 훈련\r\n","        train_acc_list = []\r\n","        with tqdm(train_data_loader,#train_data_loader를 iterative하게 반환\r\n","                total=train_data_loader.__len__(), # train_data_loader의 크기\r\n","                unit=\"batch\") as train_bar:# 한번 반환하는 smaple의 단위는 \"batch\"\r\n","            for sample in train_bar:\r\n","                train_bar.set_description(f\"Train Epoch {epoch}\")\r\n","                # 갱신할 변수들에 대한 모든 변화도를 0으로 초기화\r\n","                # 참고)https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html\r\n","                optimizer.zero_grad()\r\n","                images, labels = sample['image'], sample['label']\r\n","                # tensor를 gpu에 올리기 \r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","\r\n","                # 모델의 dropoupt, batchnormalization를 train 모드로 설정\r\n","                model.train()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.set_grad_enabled(True):\r\n","                    # 모델 예측\r\n","                    probs  = model(images).double()\r\n","                    # loss 계산\r\n","                    loss = criterion(probs, labels)\r\n","                    # 중간 노드의 gradient로\r\n","                    # backpropagation을 적용하여\r\n","                    # gradient 계산\r\n","                    loss.backward()\r\n","                    # weight 갱신\r\n","                    optimizer.step()\r\n","\r\n","                    # train accuracy 계산\r\n","                    probs  = probs.cpu().detach().numpy()\r\n","                    labels = labels.cpu().detach().numpy()\r\n","                    preds = probs > 0.5\r\n","                    batch_acc = (labels == preds).mean()\r\n","                    train_acc_list.append(batch_acc)\r\n","                    train_acc = np.mean(train_acc_list)\r\n","\r\n","                # 현재 progress bar에 현재 미니배치의 loss 결과 출력\r\n","                train_bar.set_postfix(train_loss= loss.item(),\r\n","                                      train_acc = train_acc)\r\n","                \r\n","\r\n","        # 1개 epoch학습 후 Validation 점수 계산\r\n","        valid_acc_list = []\r\n","        with tqdm(valid_data_loader,\r\n","                total=valid_data_loader.__len__(),\r\n","                unit=\"batch\") as valid_bar:\r\n","            for sample in valid_bar:\r\n","                valid_bar.set_description(f\"Valid Epoch {epoch}\")\r\n","                optimizer.zero_grad()\r\n","                images, labels = sample['image'], sample['label']\r\n","                images = images.to(device)\r\n","                labels = labels.to(device)\r\n","\r\n","                # 모델의 dropoupt, batchnormalization를 eval모드로 설정\r\n","                model.eval()\r\n","                # .forward()에서 중간 노드의 gradient를 계산\r\n","                with torch.no_grad():\r\n","                    # validation loss만을 계산\r\n","                    probs  = model(images).double()\r\n","                    valid_loss = criterion(probs, labels)\r\n","\r\n","                    # train accuracy 계산\r\n","                    probs  = probs.cpu().detach().numpy()\r\n","                    labels = labels.cpu().detach().numpy()\r\n","                    preds = probs > 0.5\r\n","                    batch_acc = (labels == preds).mean()\r\n","                    valid_acc_list.append(batch_acc)\r\n","\r\n","                valid_acc = np.mean(valid_acc_list)\r\n","                valid_bar.set_postfix(valid_loss = valid_loss.item(),\r\n","                                      valid_acc = valid_acc)\r\n","            \r\n","        # Learning rate 조절\r\n","        lr_scheduler.step()\r\n","\r\n","        # 모델 저장\r\n","        if valid_acc_max < valid_acc:\r\n","            valid_acc_max = valid_acc\r\n","            best_model = model\r\n","            MODEL = \"EfficientNet\"\r\n","            # 모델을 저장할 구글 드라이브 경로\r\n","            path = \"/content/drive/MyDrive/dacon/models/\"\r\n","            torch.save(best_model, f'{path}{fold_index}_{MODEL}_{valid_loss.item():2.4f}_epoch_{epoch}.pth')\r\n","\r\n","    # 폴드별로 가장 좋은 모델 저장\r\n","    best_models.append(best_model)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Epoch 0: 100%|██████████| 2500/2500 [29:12<00:00,  1.43batch/s, train_acc=0.914, train_loss=0.0642]\n","Valid Epoch 0: 100%|██████████| 625/625 [02:04<00:00,  5.01batch/s, valid_acc=0.925, valid_loss=0.049]\n","Train Epoch 1: 100%|██████████| 2500/2500 [29:10<00:00,  1.43batch/s, train_acc=0.916, train_loss=0.0517]\n","Valid Epoch 1: 100%|██████████| 625/625 [02:04<00:00,  5.01batch/s, valid_acc=0.926, valid_loss=0.0461]\n","Train Epoch 2: 100%|██████████| 2500/2500 [29:09<00:00,  1.43batch/s, train_acc=0.919, train_loss=0.057]\n","Valid Epoch 2: 100%|██████████| 625/625 [02:04<00:00,  5.03batch/s, valid_acc=0.926, valid_loss=0.0536]\n","Train Epoch 3: 100%|██████████| 2500/2500 [29:03<00:00,  1.43batch/s, train_acc=0.921, train_loss=0.0704]\n","Valid Epoch 3: 100%|██████████| 625/625 [02:04<00:00,  5.02batch/s, valid_acc=0.926, valid_loss=0.064]\n","Train Epoch 4:  63%|██████▎   | 1576/2500 [18:20<10:46,  1.43batch/s, train_acc=0.923, train_loss=0.0426]"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"FBwBoh5N_vZ5"},"source":["## 6. 학습 결과 확인"]},{"cell_type":"markdown","metadata":{"id":"E9lTXWY7_yKb"},"source":["## 7. 앙상블 적용"]},{"cell_type":"code","metadata":{"id":"S9dCOMWZrLm8"},"source":["model = torch.load('./EfficientNet_0.928.pth')\r\n","model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j-iJOh15yJQF"},"source":["#test Dataset 정의\r\n","sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","test_dataset = DatasetMNIST_test(\"test_dirty_mnist/\", sample_submission)\r\n","batch_size = 16\r\n","test_data_loader = DataLoader(\r\n","    test_dataset,\r\n","    batch_size = batch_size,\r\n","    shuffle = False,\r\n","    num_workers = 3,\r\n","    drop_last = False\r\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eFTkJEJD0rFQ"},"source":["predictions_list = []\r\n","# 배치 단위로 추론\r\n","prediction_df = pd.read_csv(\"sample_submission.csv\")\r\n","\r\n","# 5개의 fold마다 가장 좋은 모델을 이용하여 예측\r\n","# print(best_model)\r\n","# 0으로 채워진 array 생성\r\n","prediction_array = np.zeros([prediction_df.shape[0],\r\n","                              prediction_df.shape[1] -1])\r\n","for idx, sample in enumerate(test_data_loader):\r\n","    with torch.no_grad():\r\n","        # 추론\r\n","        model.eval()\r\n","        images = sample['image']\r\n","        images = images.to(device)\r\n","        probs  = model(images)\r\n","        probs = probs.cpu().detach().numpy()\r\n","        preds = probs\r\n","\r\n","        # 예측 결과를 \r\n","        # prediction_array에 입력\r\n","        batch_index = batch_size * idx\r\n","        prediction_array[batch_index: batch_index + images.shape[0],:]\\\r\n","                      = preds.astype(float)\r\n","                      \r\n","# 채널을 하나 추가하여 list에 append\r\n","predictions_list.append(prediction_array[...,np.newaxis])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GFsKkBnaro65","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614479890663,"user_tz":-540,"elapsed":54107,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"a6db8858-cd6a-4be6-afcf-f92ebcf9b430"},"source":["# axis = 2를 기준으로 평균\r\n","predictions_array = np.concatenate(predictions_list, axis = 2)\r\n","predictions_mean = predictions_array.mean(axis = 2)\r\n","\r\n","# 평균 값이 0.5보다 클 경우 1 작으면 0\r\n","# predictions_mean = (predictions_mean > 0.5) * 1\r\n","predictions_mean"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.99842417, 0.01340955, 0.99698669, ..., 0.98389763, 0.05129382,\n","        0.99686313],\n","       [0.01622772, 0.97145128, 0.74581873, ..., 0.0094005 , 0.03873951,\n","        0.01397544],\n","       [0.05934459, 0.02973176, 0.87512255, ..., 0.02692127, 0.06540667,\n","        0.9749732 ],\n","       ...,\n","       [0.96252429, 0.0143478 , 0.05164703, ..., 0.0369614 , 0.03178167,\n","        0.98216665],\n","       [0.05198433, 0.01811621, 0.98821974, ..., 0.0620117 , 0.13981763,\n","        0.99647141],\n","       [0.99355996, 0.91200703, 0.07288954, ..., 0.97407192, 0.99924099,\n","        0.99101263]])"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"rW0xr_P9wAEB"},"source":["## 8. 제출파일 생성"]},{"cell_type":"code","metadata":{"id":"xMa5pHWC2C1m","colab":{"base_uri":"https://localhost:8080/","height":427},"executionInfo":{"status":"ok","timestamp":1614479891731,"user_tz":-540,"elapsed":1061,"user":{"displayName":"‍이두현(학부학생/공과대학 기계공학)","photoUrl":"","userId":"08952938038466007528"}},"outputId":"274aed20-2363-4160-f710-cabe73752465"},"source":["sample_submission = pd.read_csv(\"sample_submission.csv\")\r\n","sample_submission.iloc[:,1:] = predictions_mean\r\n","sample_submission.to_csv(\"EfficientNet_0.926.csv\", index = False)\r\n","sample_submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>a</th>\n","      <th>b</th>\n","      <th>c</th>\n","      <th>d</th>\n","      <th>e</th>\n","      <th>f</th>\n","      <th>g</th>\n","      <th>h</th>\n","      <th>i</th>\n","      <th>j</th>\n","      <th>k</th>\n","      <th>l</th>\n","      <th>m</th>\n","      <th>n</th>\n","      <th>o</th>\n","      <th>p</th>\n","      <th>q</th>\n","      <th>r</th>\n","      <th>s</th>\n","      <th>t</th>\n","      <th>u</th>\n","      <th>v</th>\n","      <th>w</th>\n","      <th>x</th>\n","      <th>y</th>\n","      <th>z</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>50000</td>\n","      <td>0.998424</td>\n","      <td>0.013410</td>\n","      <td>0.996987</td>\n","      <td>0.942028</td>\n","      <td>0.992872</td>\n","      <td>0.999403</td>\n","      <td>0.017614</td>\n","      <td>0.945488</td>\n","      <td>0.998873</td>\n","      <td>0.637929</td>\n","      <td>0.017881</td>\n","      <td>0.029777</td>\n","      <td>0.022418</td>\n","      <td>0.042058</td>\n","      <td>0.048763</td>\n","      <td>0.095549</td>\n","      <td>0.055655</td>\n","      <td>0.065010</td>\n","      <td>0.012008</td>\n","      <td>0.657257</td>\n","      <td>0.994691</td>\n","      <td>0.926540</td>\n","      <td>0.017496</td>\n","      <td>0.983898</td>\n","      <td>0.051294</td>\n","      <td>0.996863</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>50001</td>\n","      <td>0.016228</td>\n","      <td>0.971451</td>\n","      <td>0.745819</td>\n","      <td>0.062009</td>\n","      <td>0.999047</td>\n","      <td>0.019482</td>\n","      <td>0.993740</td>\n","      <td>0.046878</td>\n","      <td>0.976278</td>\n","      <td>0.547279</td>\n","      <td>0.985005</td>\n","      <td>0.980480</td>\n","      <td>0.014663</td>\n","      <td>0.012684</td>\n","      <td>0.936382</td>\n","      <td>0.993138</td>\n","      <td>0.324497</td>\n","      <td>0.603298</td>\n","      <td>0.054533</td>\n","      <td>0.030471</td>\n","      <td>0.996134</td>\n","      <td>0.993582</td>\n","      <td>0.020829</td>\n","      <td>0.009400</td>\n","      <td>0.038740</td>\n","      <td>0.013975</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>50002</td>\n","      <td>0.059345</td>\n","      <td>0.029732</td>\n","      <td>0.875123</td>\n","      <td>0.997460</td>\n","      <td>0.978672</td>\n","      <td>0.022515</td>\n","      <td>0.991150</td>\n","      <td>0.356594</td>\n","      <td>0.999753</td>\n","      <td>0.327631</td>\n","      <td>0.921705</td>\n","      <td>0.893846</td>\n","      <td>0.224765</td>\n","      <td>0.565062</td>\n","      <td>0.015607</td>\n","      <td>0.998544</td>\n","      <td>0.021534</td>\n","      <td>0.974193</td>\n","      <td>0.999724</td>\n","      <td>0.047407</td>\n","      <td>0.995504</td>\n","      <td>0.182060</td>\n","      <td>0.996152</td>\n","      <td>0.026921</td>\n","      <td>0.065407</td>\n","      <td>0.974973</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>50003</td>\n","      <td>0.991719</td>\n","      <td>0.970988</td>\n","      <td>0.017428</td>\n","      <td>0.120970</td>\n","      <td>0.002542</td>\n","      <td>0.935888</td>\n","      <td>0.994521</td>\n","      <td>0.135545</td>\n","      <td>0.975706</td>\n","      <td>0.069510</td>\n","      <td>0.997831</td>\n","      <td>0.964497</td>\n","      <td>0.987209</td>\n","      <td>0.014662</td>\n","      <td>0.007123</td>\n","      <td>0.990588</td>\n","      <td>0.023332</td>\n","      <td>0.948096</td>\n","      <td>0.025124</td>\n","      <td>0.999339</td>\n","      <td>0.005154</td>\n","      <td>0.039242</td>\n","      <td>0.035161</td>\n","      <td>0.994571</td>\n","      <td>0.109704</td>\n","      <td>0.970242</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>50004</td>\n","      <td>0.020268</td>\n","      <td>0.006498</td>\n","      <td>0.975062</td>\n","      <td>0.013067</td>\n","      <td>0.997252</td>\n","      <td>0.991559</td>\n","      <td>0.017233</td>\n","      <td>0.011030</td>\n","      <td>0.025967</td>\n","      <td>0.023196</td>\n","      <td>0.007787</td>\n","      <td>0.966103</td>\n","      <td>0.998403</td>\n","      <td>0.013573</td>\n","      <td>0.987371</td>\n","      <td>0.108054</td>\n","      <td>0.994401</td>\n","      <td>0.424204</td>\n","      <td>0.996948</td>\n","      <td>0.999335</td>\n","      <td>0.629784</td>\n","      <td>0.201701</td>\n","      <td>0.998897</td>\n","      <td>0.008450</td>\n","      <td>0.189819</td>\n","      <td>0.059704</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>54995</td>\n","      <td>0.035252</td>\n","      <td>0.933776</td>\n","      <td>0.995015</td>\n","      <td>0.278911</td>\n","      <td>0.012578</td>\n","      <td>0.044641</td>\n","      <td>0.990105</td>\n","      <td>0.997664</td>\n","      <td>0.059357</td>\n","      <td>0.226412</td>\n","      <td>0.745159</td>\n","      <td>0.644660</td>\n","      <td>0.033969</td>\n","      <td>0.544838</td>\n","      <td>0.962749</td>\n","      <td>0.009920</td>\n","      <td>0.047023</td>\n","      <td>0.899548</td>\n","      <td>0.031221</td>\n","      <td>0.972405</td>\n","      <td>0.458758</td>\n","      <td>0.621913</td>\n","      <td>0.995556</td>\n","      <td>0.043435</td>\n","      <td>0.991228</td>\n","      <td>0.145159</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>54996</td>\n","      <td>0.987062</td>\n","      <td>0.819498</td>\n","      <td>0.996045</td>\n","      <td>0.055221</td>\n","      <td>0.195513</td>\n","      <td>0.155926</td>\n","      <td>0.261240</td>\n","      <td>0.228457</td>\n","      <td>0.877037</td>\n","      <td>0.992175</td>\n","      <td>0.031062</td>\n","      <td>0.789515</td>\n","      <td>0.072910</td>\n","      <td>0.056536</td>\n","      <td>0.982915</td>\n","      <td>0.978822</td>\n","      <td>0.295691</td>\n","      <td>0.057267</td>\n","      <td>0.723913</td>\n","      <td>0.094607</td>\n","      <td>0.046266</td>\n","      <td>0.192034</td>\n","      <td>0.041330</td>\n","      <td>0.972057</td>\n","      <td>0.134651</td>\n","      <td>0.994649</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>54997</td>\n","      <td>0.962524</td>\n","      <td>0.014348</td>\n","      <td>0.051647</td>\n","      <td>0.994151</td>\n","      <td>0.023805</td>\n","      <td>0.989746</td>\n","      <td>0.006073</td>\n","      <td>0.019636</td>\n","      <td>0.326801</td>\n","      <td>0.379597</td>\n","      <td>0.985785</td>\n","      <td>0.611621</td>\n","      <td>0.944593</td>\n","      <td>0.032773</td>\n","      <td>0.998933</td>\n","      <td>0.998070</td>\n","      <td>0.008864</td>\n","      <td>0.167909</td>\n","      <td>0.011464</td>\n","      <td>0.993763</td>\n","      <td>0.981670</td>\n","      <td>0.999448</td>\n","      <td>0.978114</td>\n","      <td>0.036961</td>\n","      <td>0.031782</td>\n","      <td>0.982167</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>54998</td>\n","      <td>0.051984</td>\n","      <td>0.018116</td>\n","      <td>0.988220</td>\n","      <td>0.032516</td>\n","      <td>0.010978</td>\n","      <td>0.201375</td>\n","      <td>0.992291</td>\n","      <td>0.214815</td>\n","      <td>0.704719</td>\n","      <td>0.975172</td>\n","      <td>0.062060</td>\n","      <td>0.608052</td>\n","      <td>0.038642</td>\n","      <td>0.046520</td>\n","      <td>0.034405</td>\n","      <td>0.025420</td>\n","      <td>0.998280</td>\n","      <td>0.998160</td>\n","      <td>0.023423</td>\n","      <td>0.988335</td>\n","      <td>0.215334</td>\n","      <td>0.048262</td>\n","      <td>0.999095</td>\n","      <td>0.062012</td>\n","      <td>0.139818</td>\n","      <td>0.996471</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>54999</td>\n","      <td>0.993560</td>\n","      <td>0.912007</td>\n","      <td>0.072890</td>\n","      <td>0.051128</td>\n","      <td>0.633925</td>\n","      <td>0.992621</td>\n","      <td>0.061386</td>\n","      <td>0.305922</td>\n","      <td>0.910127</td>\n","      <td>0.158139</td>\n","      <td>0.079683</td>\n","      <td>0.609848</td>\n","      <td>0.988904</td>\n","      <td>0.178475</td>\n","      <td>0.018864</td>\n","      <td>0.103298</td>\n","      <td>0.154200</td>\n","      <td>0.987573</td>\n","      <td>0.970480</td>\n","      <td>0.147232</td>\n","      <td>0.050158</td>\n","      <td>0.078879</td>\n","      <td>0.936754</td>\n","      <td>0.974072</td>\n","      <td>0.999241</td>\n","      <td>0.991013</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 27 columns</p>\n","</div>"],"text/plain":["      index         a         b  ...         x         y         z\n","0     50000  0.998424  0.013410  ...  0.983898  0.051294  0.996863\n","1     50001  0.016228  0.971451  ...  0.009400  0.038740  0.013975\n","2     50002  0.059345  0.029732  ...  0.026921  0.065407  0.974973\n","3     50003  0.991719  0.970988  ...  0.994571  0.109704  0.970242\n","4     50004  0.020268  0.006498  ...  0.008450  0.189819  0.059704\n","...     ...       ...       ...  ...       ...       ...       ...\n","4995  54995  0.035252  0.933776  ...  0.043435  0.991228  0.145159\n","4996  54996  0.987062  0.819498  ...  0.972057  0.134651  0.994649\n","4997  54997  0.962524  0.014348  ...  0.036961  0.031782  0.982167\n","4998  54998  0.051984  0.018116  ...  0.062012  0.139818  0.996471\n","4999  54999  0.993560  0.912007  ...  0.974072  0.999241  0.991013\n","\n","[5000 rows x 27 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"VPcpcWHTITid"},"source":[""],"execution_count":null,"outputs":[]}]}